{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the preprocessed data for ML model building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images/ml_modeling_images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "def save_model(model, folder_path=\"models\", file_name=\"untitled_model.sav\"):\n",
    "    pickle.dump(model, open(os.path.join(folder_path, file_name), 'wb'))\n",
    "\n",
    "ALZHEIMERS_PATH = \"dataset/afterpreprocessing\"\n",
    "alzheimers_dfs = []\n",
    "file_names = [\"Overall_Health\", \"Mental_Health\", \"Smoking_and_Alcohol_Use\", \"Screenings_and_Vaccines\", \"Nutrition_Physical_Activity_Obesity\", \"Caregiving\", \"Cognitive_Decline\"]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    csv_path = os.path.join(ALZHEIMERS_PATH, f'{file_names[i]}.csv')\n",
    "    df = pd.read_csv(csv_path)\n",
    "    alzheimers_dfs.append(df)\n",
    "\n",
    "alzheimers_dfs[0].head()\n",
    "\n",
    "all_alzheimers_data = pd.read_csv(os.path.join(ALZHEIMERS_PATH, f'all_alzheimers_data.csv'))\n",
    "\n",
    "all_alzheimers_data.fillna(0, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Feature Set With Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Visualizing a Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from graphviz import Source\n",
    "\n",
    "MODELS_PATH = os.path.join(PROJECT_ROOT_DIR, \"models\")\n",
    "DECISION_TREE_PATH = os.path.join(MODELS_PATH, 'decision_tree')\n",
    "\n",
    "def FullDecisionTreeModel(df):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "    for i in range(len(df)):\n",
    "        input = df[i].drop(['LocationDesc'], axis=1)\n",
    "        target = df[i]['LocationDesc']\n",
    "        tree_clf.fit(input, target)\n",
    "        graph = Source(export_graphviz(tree_clf, out_file=None, feature_names=input.columns, class_names=target, rounded=True, filled=True))\n",
    "        graph.format = 'png'\n",
    "        graph.render( IMAGES_PATH + '/decision_tree/' + file_names[i], view=False)\n",
    "        filename = f'{file_names[i]}_decision_tree_model.sav'\n",
    "        save_model(tree_clf, DECISION_TREE_PATH, filename)\n",
    "\n",
    "FullDecisionTreeModel(alzheimers_dfs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Feature Set With Apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apriori https://github.com/ymoch/apyori\n",
    "\n",
    "from apyori import apriori\n",
    "\n",
    "def AprioriModel(df):\n",
    "    for i in range(len(df)):\n",
    "        records = []\n",
    "        for j in range(0, df.shape[0]):\n",
    "            records.append([str(df.values[j, k]) for k in range(0, 33)])\n",
    "        association_rules = apriori(records, min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)\n",
    "        association_results = list(association_rules)\n",
    "        print(association_results)\n",
    "AprioriModel(all_alzheimers_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Feature Set with Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Detection algorthim \n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def IsolationForestModel(df):\n",
    "    for i in range(len(df)):\n",
    "        input = df[i].drop(['LocationDesc'], axis=1)\n",
    "        clf = IsolationForest(max_samples=100, random_state=42)\n",
    "        clf.fit(input)\n",
    "\n",
    "IsolationForestModel(alzheimers_dfs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Feature Set With Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "OneClassSVM_PATH = os.path.join(MODELS_PATH, 'one_class_svm')\n",
    "\n",
    "def FullOneClassSVMModel(df):\n",
    "    input = df.drop(columns=['LocationDesc','AgeGroup'])\n",
    "    # define and fit outlier detection model\n",
    "    one_class_svm_clf = OneClassSVM(gamma='auto').fit(input)\n",
    "    save_model(one_class_svm_clf, OneClassSVM_PATH, 'alzheimers_one_class_svm_model.sav')\n",
    "\n",
    "FullOneClassSVMModel(all_alzheimers_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def top_feature_selector(df, top_num=20):\n",
    "    input = df.drop(['LocationDesc'], axis=1)\n",
    "    target = df['LocationDesc']\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=3)\n",
    "    fit = bestfeatures.fit(input,target)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(input.columns)\n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "    print(featureScores.nlargest(top_num,'Score'))  #print 10 best features\n",
    "    print('----------------------------------------------------')\n",
    "    return dfcolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant features\n",
    "all_alzheimers_data = all_alzheimers_data.drop(columns=[\"Duration of caregiving among older adults\", \n",
    "                                                        \"Intensity of caregiving among older adults\", \n",
    "                                                        \"Talked with health care professional about subjective cognitive decline or memory loss\",\n",
    "                                                        \"Expect to provide care for someone in the next two years\",\n",
    "                                                        \"Provide care for a friend or family member in past month\",\n",
    "                                                        \"Provide care for someone with cognitive impairment within the past month\",\n",
    "                                                        \"Self-rated health (fair to poor health)\",\n",
    "                                                        \"Self-rated health (good to excellent health)\",\n",
    "                                                        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataframe by AgeGroup\n",
    "alzheimers_data_age0 = all_alzheimers_data.loc[all_alzheimers_data['AgeGroup'] == 0].reset_index().drop(['index', 'AgeGroup'], axis=1) # 50-64 y/o\n",
    "alzheimers_data_age1 = all_alzheimers_data.loc[all_alzheimers_data['AgeGroup'] == 1].reset_index().drop(['index', 'AgeGroup'], axis=1) # 65+ y/o\n",
    "alzheimers_data_age2 = all_alzheimers_data.loc[all_alzheimers_data['AgeGroup'] == 2].reset_index().drop(['index', 'AgeGroup'], axis=1) # Overall (50+ y/o)\n",
    "\n",
    "alzheimers_data_age0.head()\n",
    "alzheimers_data_age1.head()\n",
    "alzheimers_data_age2.head()\n",
    "\n",
    "# Get top features for each AgeGroup\n",
    "age0_features = top_feature_selector(alzheimers_data_age0)\n",
    "age1_features = top_feature_selector(alzheimers_data_age1)\n",
    "age2_features = top_feature_selector(alzheimers_data_age2)\n",
    "\n",
    "alzheimers_data_age0 = alzheimers_data_age0.drop('LocationDesc', axis=1)\n",
    "alzheimers_data_age1 = alzheimers_data_age1.drop('LocationDesc', axis=1)\n",
    "alzheimers_data_age2 = alzheimers_data_age2.drop('LocationDesc', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the top 20 features\n",
    "alzheimers_data_age0 = alzheimers_data_age0.drop(columns=age0_features[0][20:].tolist(), axis=1)\n",
    "alzheimers_data_age1 = alzheimers_data_age1.drop(columns=age1_features[0][20:].tolist(), axis=1)\n",
    "alzheimers_data_age2 = alzheimers_data_age2.drop(columns=age2_features[0][20:].tolist(), axis=1)\n",
    "\n",
    "alzheimers_data_age0.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Feature Set With Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReducedDecisionTreeModel(df):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "    input =  df.drop(columns='LocationDesc')\n",
    "    target = df['LocationDesc']\n",
    "    tree_clf.fit(input, target)\n",
    "    graph = Source(export_graphviz(tree_clf, out_file=None, feature_names=input.columns, class_names=target, rounded=True, filled=True))\n",
    "    graph.format = 'png'\n",
    "    graph.render( IMAGES_PATH + '/decision_tree/all_alzheimers_data', view=False)\n",
    "    filename = 'all_alzheimers_data_decision_tree_model.sav'\n",
    "    save_model(tree_clf, DECISION_TREE_PATH, filename)\n",
    "\n",
    "ReducedDecisionTreeModel(all_alzheimers_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Feature Set With K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m KMeans\n\u001b[1;32m      3\u001b[0m KMEANS_PATH \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(MODELS_PATH, \u001b[39m'\u001b[39m\u001b[39mkmeans\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m kmeans_clf \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, n_init\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(alzheimers_data_age0)\n\u001b[1;32m      7\u001b[0m save_model(kmeans_clf, KMEANS_PATH, \u001b[39m'\u001b[39m\u001b[39malzheimers_kmeans_model.sav\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cpsc-483/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1146\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m \n\u001b[1;32m   1114\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1138\u001b[0m     X,\n\u001b[1;32m   1139\u001b[0m     accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1144\u001b[0m )\n\u001b[0;32m-> 1146\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_params(X)\n\u001b[1;32m   1147\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m   1148\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cpsc-483/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:937\u001b[0m, in \u001b[0;36mKMeans._check_params\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_params\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    936\u001b[0m     \u001b[39m# n_init\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_init \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m:\n\u001b[1;32m    938\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mn_init should be > 0, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_init\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    939\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_init \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_init\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KMEANS_PATH = os.path.join(MODELS_PATH, 'kmeans')\n",
    "\n",
    "kmeans_clf = KMeans(n_clusters=2, random_state=0, n_init=\"auto\").fit(alzheimers_data_age0)\n",
    "\n",
    "save_model(kmeans_clf, KMEANS_PATH, 'alzheimers_kmeans_model.sav')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduced Feature Set With Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "def ReducedOneClassSVMModel(df):\n",
    "    input = df\n",
    "    # define and fit outlier detection model\n",
    "    one_class_svm_clf = OneClassSVM(gamma='auto').fit(input)\n",
    "    save_model(one_class_svm_clf, OneClassSVM_PATH, 'alzheimers_one_class_svm_model.sav')\n",
    "\n",
    "ReducedOneClassSVMModel(alzheimers_data_age0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_decision_tree_model = pickle.load(open(os.path.join(DECISION_TREE_PATH, \"Overall_Health_decision_tree_model.sav\"), 'rb'))\n",
    "loaded_kmeans_model = pickle.load(open(os.path.join(KMEANS_PATH, \"alzheimers_kmeans_model.sav\"), 'rb'))\n",
    "loaded_one_class_svm_model = pickle.load(open(os.path.join(OneClassSVM_PATH, \"alzheimers_one_class_svm_model.sav\"), 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc-483",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
